{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Funktionen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "    \n",
    "target = 'SalePrice'\n",
    "\n",
    "def checkFeature(feature):\n",
    "    checkNAs(feature)\n",
    "    checkForNegatives(feature)\n",
    "    overview(feature)\n",
    "    plotDistribution(feature)\n",
    "    if feature != target:\n",
    "        plotRelationToTarget(feature)\n",
    "    \n",
    "def checkNAs(feature):\n",
    "    if train[feature].isna().sum() > 0:\n",
    "        print(bcolors.FAIL + \"Sum NAs: \" + str(train[feature].isna().sum()))\n",
    "    else:\n",
    "        print(bcolors.OKGREEN + \"No NAs\" +bcolors.ENDC)\n",
    "\n",
    "def checkForNegatives(feature):\n",
    "    if any(train[feature]<0):\n",
    "        print (bcolors.WARNING + \"Warning feature has negative value!\" + bcolors.ENDC)\n",
    "    else:\n",
    "        print (bcolors.OKGREEN + \"No negative values\" + bcolors.ENDC)\n",
    "\n",
    "def plotDistribution(feature):\n",
    "    sns.distplot(train[feature], fit=norm);\n",
    "    fig = plt.figure()\n",
    "    res = stats.probplot(train[feature], plot=plt)\n",
    "    \n",
    "def plotRelationToTarget(feature):\n",
    "    data_temp = pd.concat([train[target], train[feature]], axis=1)\n",
    "    data_temp.plot.scatter(x=feature, y=target, ylim=(0,800000));\n",
    "        \n",
    "def overview(feature):\n",
    "    print(train[feature].describe())\n",
    "    print(bcolors.HEADER + \"Head\" +bcolors.ENDC)\n",
    "    print(train[feature].head(3))\n",
    "    \n",
    "def printSkewKurt(feature):\n",
    "    print(\"Skewness: %f\" % train[feature].skew())\n",
    "    print(\"Kurtosis: %f\" % train[feature].kurt())\n",
    "    \n",
    "def calculate_performance(prediction, actual, scaler):\n",
    "    if scaler == True:\n",
    "        p = scaler.inverse_transform(prediction.reshape(-1,1))\n",
    "        a = scaler.inverse_transform(actual.reshape(-1,1))\n",
    "    else:\n",
    "        p = prediction\n",
    "        a = actual\n",
    "        \n",
    "    mse = mean_squared_error(a, p)\n",
    "    err = np.sqrt(mse)\n",
    "    r2 = r2_score(a, p)\n",
    "    mae = median_absolute_error(a, p)\n",
    "    \n",
    "    return (mse, err, r2, mae)\n",
    "\n",
    "def print_performance(measure_tuple):\n",
    "    \n",
    "    mse = measure_tuple[0]\n",
    "    err = measure_tuple[1]\n",
    "    r2 = measure_tuple[2]\n",
    "    mae = measure_tuple[3]\n",
    "    \n",
    "    print(\"Mean squared error is {}\".format(str(mse)))\n",
    "    print(\"Positive mean error is {}\".format(str(err)))\n",
    "    print(\"Overall RÂ² is {}\".format(str(r2)))\n",
    "    print(\"Median absolute error is {}\".format(str(mae)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
